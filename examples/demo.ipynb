{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balanced Active Inference - Demonstration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import our custom modules\n",
    "from src.data_generation import generate_friedman_data, split_data\n",
    "from src.models import ActiveInferenceModels, train_predictive_models\n",
    "from src.sampling_methods import compute_sampling_probabilities\n",
    "from src.experiment import run_simulation_experiment\n",
    "from src.visualization import (\n",
    "    plot_comparison_results,\n",
    "    plot_uncertainty_distribution,\n",
    "    plot_sampling_allocation,\n",
    "    save_results_to_csv\n",
    ")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "print(\"Packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Generation\n",
    "\n",
    "We generate synthetic data using the Friedman nonlinear function:\n",
    "\n",
    "$$Y = 10\\sin(\\pi X_1 X_2) + 20(X_3 - 0.5)^2 + 10X_4 + 5X_5 + \\epsilon$$\n",
    "\n",
    "where $X_1, \\ldots, X_5 \\sim \\text{Uniform}(0, 1)$ and $\\epsilon \\sim N(0, 0.09)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "n_samples = 10000\n",
    "n_features = 10\n",
    "\n",
    "X, y = generate_friedman_data(\n",
    "    n_samples=n_samples,\n",
    "    n_features=n_features,\n",
    "    noise_std=0.3,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "print(f\"Generated {n_samples} samples with {n_features} features\")\n",
    "print(f\"Response variable statistics:\")\n",
    "print(f\"  Mean: {y.mean():.4f}\")\n",
    "print(f\"  Std:  {y.std():.4f}\")\n",
    "print(f\"  Min:  {y.min():.4f}\")\n",
    "print(f\"  Max:  {y.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into Training and Test Sets\n",
    "\n",
    "We use 50% of data for training and 50% for testing (inference population)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    X, y,\n",
    "    test_size=0.5,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(y_train)}\")\n",
    "print(f\"Test set size: {len(y_test)}\")\n",
    "print(f\"True population mean: {y_test.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train Predictive Models\n",
    "\n",
    "We train two models:\n",
    "1. **Label Model**: Predicts the response variable\n",
    "2. **Error Model**: Estimates prediction uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = ActiveInferenceModels(\n",
    "    label_params={\n",
    "        'n_estimators': 1000,\n",
    "        'learning_rate': 0.001,\n",
    "        'max_depth': 7,\n",
    "        'random_state': 0\n",
    "    },\n",
    "    error_params={\n",
    "        'n_estimators': 1000,\n",
    "        'learning_rate': 0.001,\n",
    "        'max_depth': 7,\n",
    "        'random_state': 0\n",
    "    }\n",
    ")\n",
    "\n",
    "# Train models\n",
    "print(\"Training models...\")\n",
    "models.fit(X_train, y_train)\n",
    "print(\"Models trained successfully!\")\n",
    "\n",
    "# Generate predictions and uncertainty estimates on test set\n",
    "y_pred, uncertainty = models.predict(X_test)\n",
    "error_pred = models.error_model.predict(X_test)\n",
    "\n",
    "# Evaluate prediction quality\n",
    "mse = np.mean((y_test - y_pred) ** 2)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = np.mean(np.abs(y_test - y_pred))\n",
    "\n",
    "print(f\"\\nLabel Model Performance:\")\n",
    "print(f\"  RMSE: {rmse:.4f}\")\n",
    "print(f\"  MAE:  {mae:.4f}\")\n",
    "print(f\"\\nUncertainty Statistics:\")\n",
    "print(f\"  Mean: {uncertainty.mean():.4f}\")\n",
    "print(f\"  Std:  {uncertainty.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Uncertainty Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot uncertainty distribution\n",
    "plot_uncertainty_distribution(uncertainty, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sampling Strategy Comparison\n",
    "\n",
    "We demonstrate active sampling allocation based on uncertainty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute sampling probabilities for a specific budget\n",
    "budget = 0.1  # 10% sampling rate\n",
    "tau = 0.5  # Balance parameter\n",
    "\n",
    "inclusion_probs = compute_sampling_probabilities(\n",
    "    uncertainty,\n",
    "    budget=budget,\n",
    "    tau=tau\n",
    ")\n",
    "\n",
    "print(f\"Sampling budget: {budget * 100:.1f}%\")\n",
    "print(f\"Expected sample size: {inclusion_probs.sum():.1f}\")\n",
    "print(f\"Inclusion probability range: [{inclusion_probs.min():.4f}, {inclusion_probs.max():.4f}]\")\n",
    "\n",
    "# Visualize sampling allocation\n",
    "plot_sampling_allocation(uncertainty, inclusion_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run Simulation Experiment\n",
    "\n",
    "We compare four sampling methods across different budgets:\n",
    "1. Classical Simple Random Sampling (baseline)\n",
    "2. Uniform Poisson Sampling (baseline)\n",
    "3. Active Poisson Sampling (baseline)\n",
    "4. **Cube Active Sampling (our method)**\n",
    "\n",
    "**Note:** This may take several minutes depending on your hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define budgets to evaluate\n",
    "budgets = np.arange(0.05, 0.3, 0.02)\n",
    "\n",
    "# Run simulation (reduce n_trials for faster testing)\n",
    "print(\"Starting simulation experiment...\")\n",
    "print(f\"Budgets: {budgets}\")\n",
    "print(f\"Number of trials per budget: 1000\")\n",
    "\n",
    "results = run_simulation_experiment(\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    uncertainty=uncertainty,\n",
    "    error_pred=error_pred,\n",
    "    budgets=budgets,\n",
    "    n_trials=1000,  # Reduce to 100 for quick testing\n",
    "    confidence_level=0.95,\n",
    "    tau=0.5,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "print(\"\\nSimulation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display RMSE results\n",
    "print(\"RMSE Results:\")\n",
    "print(results['rmse'])\n",
    "\n",
    "print(\"\\nInterval Width Results:\")\n",
    "print(results['interval_width'])\n",
    "\n",
    "print(\"\\nCoverage Rate Results:\")\n",
    "print(results['coverage'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Results\n",
    "\n",
    "Create publication-quality comparison plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive comparison plot\n",
    "plot_comparison_results(\n",
    "    results,\n",
    "    output_path='results/comparison.pdf',\n",
    "    figsize=(15, 5),\n",
    "    font_size=18,\n",
    "    dpi=300\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Results\n",
    "\n",
    "Export all results to CSV files for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to CSV\n",
    "save_results_to_csv(results, output_dir='results')\n",
    "\n",
    "print(\"\\nAll results saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Relative Performance\n",
    "\n",
    "Compute relative improvement of cube active sampling over baselines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute improvement over classical sampling\n",
    "rmse_df = results['rmse']\n",
    "\n",
    "improvement_classical = (\n",
    "    (rmse_df['classical'] - rmse_df['cube_active']) / rmse_df['classical'] * 100\n",
    ")\n",
    "\n",
    "improvement_uniform = (\n",
    "    (rmse_df['uniform'] - rmse_df['cube_active']) / rmse_df['uniform'] * 100\n",
    ")\n",
    "\n",
    "print(\"RMSE Improvement of Cube Active Sampling:\")\n",
    "print(f\"\\nOver Classical SRS:\")\n",
    "print(f\"  Mean: {improvement_classical.mean():.2f}%\")\n",
    "print(f\"  Max:  {improvement_classical.max():.2f}%\")\n",
    "\n",
    "print(f\"\\nOver Uniform Poisson:\")\n",
    "print(f\"  Mean: {improvement_uniform.mean():.2f}%\")\n",
    "print(f\"  Max:  {improvement_uniform.max():.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
